{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\nProcessing text data set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import sys\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "BASE_DIR = '/Users/kimardenmiller/Documents/Local Data/NLP_Embeddings/'\n",
    "GLOVE_DIR = BASE_DIR + 'glove.6B/'\n",
    "TEXT_DATA_DIR = BASE_DIR + '20_newsgroup/'\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# first, build index mapping words in the embeddings set to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "# f = pd.read_csv(os.path.join(GLOVE_DIR, 'glove.6B.100d_2.txt'), sep=\" \", header=None).values\n",
    "# for line in f:\n",
    "#     word = line[0]\n",
    "#     coefficients = np.asarray(line[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefficients\n",
    "# \n",
    "# print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text data set')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for newsgroup in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, newsgroup)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[newsgroup] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                if sys.version_info < (3,):\n",
    "                    f = open(fpath)\n",
    "                else:\n",
    "                    f = open(fpath, encoding='latin-1')\n",
    "                texts.append(f.read())\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "                \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}